<!DOCTYPE html>
<html>
    <head>
        <link type = "text/css" rel="stylesheet" href = "stylesheet.css"/>
        <title>Ian Rankin</title>
    </head>
    <body>
        <div class = "main">
            <div class = "header">
                <ul>
                    <a class = "button" href="http://ianran.github.io/index"><li>Home</li></a>
                    <a class = "button" href="http://ianran.github.io/kinectRobot"><li>Kinect Robot</li></a>
                    <a class = "button" href="http://ianran.github.io/legoSwerve"><li>Lego Swerve</li></a>
                    <a class = "button" href="http://chicago.cubs.mlb.com/index.jsp?c_id=chc"><li>Fourth Item</li></a>
                </ul>
            </div>
            
            
            
            <h1>Kinect Robot</h1>
            <h4><i>An Autonmous robot for finding paths automaticlly from depth image data from the Kinect.</i></h4>
            <h4 class = "workProgress">Project is a work in progress</h4>
            
            <img class = "SidePhoto" src = "http://ianran.github.io/thumb_IMG_2188.jpg"/>
            <p class = "side">
            The Kinect robot is a large project I am currently working on. The goal of the project is to
            complete a robot that can map out and avoid obstucules so that the robot can find it's way to the
            end target as fast as effciently as possible.
            </p>
            
            <p class = "side">
            The main data the robot will be using is a 
            <a href = "https://www.microsoft.com/en-us/kinectforwindows/meetkinect/default.aspx">Microsoft Kinect</a>.
            These sensors originaly designed for the xbox as a human input device are a very impressivse sensor for it's price.
            The Kinect gives back a depth image, which is a image that the pixels are a distance away from the camera rather
            then RGB data. These depth images are particuallry interesting, because from the location of an idividual pixel
            we can get the x and y angle the pixel is from the Kinect. Once you have 2 angles and the distance from the Kinect,
            it is easy to get a 3D point from every single pixel in the depth image.
            Once there is a 3D point for every pixel, the software will then go through an add each point to a 2D top view map of
            the suroundings of the robot so it can run the path-finding algorithems.
            </p>
            
            <p class = "side">
            Image of the Adafruit 9-DOF Absolute orientation IMU fusion breakout - BN0055
            </p>
            
        </div>
    </body>
</html>

